\documentclass[onecolumn,unpublished]{quantumarticle}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage[caption=false]{subfig}
\usepackage[colorlinks]{hyperref}
\usepackage[all]{hypcap}
\usepackage{tikz}
\usepackage{relsize}
\usepackage{color,soul}
\usepackage[utf8]{inputenc}
\usepackage{capt-of}
\usepackage[numbers]{natbib}
\usetikzlibrary{decorations.pathreplacing}

% Boo Roman Numerals.
\renewcommand\thesection{\arabic{section}}

% Hyperlinked references to figures, theorems, etc.
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{definition}
\newtheorem{theorem}[definition]{Theorem}
\theoremstyle{definition}
\newtheorem{lemma}[definition]{Lemma}
\newcommand{\eq}[1]{\hyperref[eq:#1]{Equation~\ref*{eq:#1}}}
\renewcommand{\sec}[1]{\hyperref[sec:#1]{Section~\ref*{sec:#1}}}
\DeclareRobustCommand{\app}[1]{\hyperref[app:#1]{Appendix~\ref*{app:#1}}}
\newcommand{\fig}[1]{\hyperref[fig:#1]{Figure~\ref*{fig:#1}}}
\newcommand{\tbl}[1]{\hyperref[tbl:#1]{Table~\ref*{tbl:#1}}}
\newcommand{\theoremref}[1]{\hyperref[theorem:#1]{Theorem~\ref*{theorem:#1}}}
\newcommand{\definitionref}[1]{\hyperref[definition:#1]{Definition~\ref*{definition:#1}}}

% Python style for highlighting
\usepackage{listings}
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12}
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self,controlledby,with,quint,let,carryinto,store},
keywordstyle=\ttb\color{deepblue},
emph={measure,__init__},
emphstyle=\ttb\color{deepblue},
stringstyle=\color{deepgreen},
showstringspaces=false
}}
\lstnewenvironment{python}[1][]
{\pythonstyle\lstset{#1}}{}

\input{qcircuit}

\title{Low depth quantum adders and waiting for magic states}
\date{\today}
\author{Craig Gidney}
\email{craiggidney@google.com}
\affiliation{Google Inc., Santa Barbara, California 93117, USA}

\begin{document}
\maketitle

\begin{abstract}
    We improve the Toffoli count of low depth quantum adders, and analyze how their spacetime cost reacts to having a limited number of magic state factories.
    We present an out-of-place carry lookahead adder with a Toffoli count of $4n$ (vs $5n$ in previous work by Draper et al) and a corresponding in-place Toffoli count of $7n$ (vs $10n$ in previous work by Draper et al).
    We also consider parallelizing over larger blocks of bits of size $b$, which reduces the Toffoli count to $3n + 5n/b$ out-of-place and $5n + 5n/b$ in-place at the cost of the reaction depth depending linearly on $b$.
    We estimate the spacetime volume of these adders, and adders from previous work, for various register sizes and factory counts under plausible assumptions for a large scale quantum computer based on the surface code and superconducting qubits.
\end{abstract}

\section{Introduction}

In the classical computing world, low depth adders are ubiquitous.
Even the original 8-bit Intel 8008 chip had a carry-lookahead adder \cite{shirriff2020reverseengineer8008}.
In the context of fault tolerant quantum computation, it's not clear if low depth adders will enjoy the same popularity.
The problem is that low depth adders appear to require five to ten times as many Toffolis as ripple carry adders \cite{draper2004lookaheadadder,cuccaro2004adder,gidney2018halving} and they need to apply these operations at a much faster rate, implying a huge space overhead due to the need for many, many magic state factories.

In the surface code, non-Clifford operations such as the T gate and the Toffoli gate are not native operations.
They have to be emulated using roundabout techniques like magic state distillation \cite{bravyi2005magicstate}.
Magic state factories are expected to be expensive.
For example in \cite{gidney2019catalyzed} a factory covers hundreds of thousands of physical qubits and produces a magic state every 165 microseconds (although new techniques are reducing the cost \cite{litinski2019magicnotcostly}).
If a quantum computer isn't large enough to hold many magic state factories, running a low depth adder is pointless because the adder will simply bottleneck waiting for magic states.

Suppose we have a quantum computer with a control system reaction time of 10 microseconds and factories that each produce a state every 165 microseconds as in \cite{gidney2019autoccz}.
Using a ripple-carry adder and reaction limited quantum computation \cite{fowler2012timeoptimal,gidney2019autoccz}, you would need 17 magic state factories before the ripple carry process was running at top speed.
If a carry lookahead adder requires five times more Toffolis, this implies you need at least $17 \cdot 5 = 85$ magic state factories before the carry lookahead adder can possibly outpace the ripple carry adder.
In other words, it looks like you have to dedicate tens of millions of physical qubits to magic state distillation before the carry lookahead adder even has a chance at being better.
For comparison, recent estimates of the cost of quantum chemistry computations involving FeMoCo covered only four million physical qubits \cite{lee2020hypercontractionchemistry}.

\begin{table}
\centering
\resizebox{\linewidth}{!}{
\input{gen/comparison_table.tex}
}
    \caption{Comparison of the constructions in this paper with some other adder constructions.
    Note how ripple carry adders dominate until extremely large problem sizes and factory counts.
    The value $V(n,f)$ is an estimate in logical qubitseconds of the spacetime volume required to execute an $n$-bit adder using $f$ magic state factories.
    It is estimated using the formula $\text{Tof}_n \cdot c_{\text{area}} \cdot c_{\text{period}} + \text{Space}_n \cdot \max(D_n \cdot c_{\text{rtt}}, c_{\text{period}} \cdot \text{Tof}_n / (\text{Depth}_n \cdot u))$ where $c_{\text{area}}=72$ is the estimated footprint of a magic state factory, $c_{\text{period}}=165$us is the estimated duration of a magic state factory, $c_{\text{rtt}}=10$us is the estimated round trip reaction time of the classical control system, $u \in [0, 1]$ is a per-adder tweak factor to account for constructions ending with dead time where they consume Toffolis more slowly, $\text{Tof}_n$ is the Toffoli count at $n$, $\text{Depth}_n$ is the reaction depth at $n$, and $\text{Space}_n$ is the workspace at $n$ plus data overhead ($2n$ for inplace adders and $3n$ for out-of-place adders). This table is generated by the ancillary file \texttt{comparison\_table.py}.
    }
    \label{tab:comparison}
\end{table}

Hopefully the trouble with choosing to use a low depth adder is now clear to the reader.
Our goal in this paper is to reduce that amount of trouble, by optimizing the cost of these adders.
We start in [SECTION] by quantizing the classical Brett-Kung adder [CITE] and using temporary logical-ANDs \cite{gidney2018halving}, resulting in a carry lookahead adder with lower Toffoli counts than in previous work.
Then, in [SECTION], we begin sacrificing parallelism to further lower the Toffoli overhead.
Instead of operating on every bit in parallel, we split the problem into blocks and operate on the blocks in parallel.
Finally, in [SECTION], we estimate the spacetime volume of our adders and previous adders in order to understand the parameter regimes in which various adders dominate.
Finally, in [SECTION], we summarize our results and give some additional caveats.

\section{Carry Lookahead Adder}

The Brett-Kung adder [CITE] is a classical binary adder circuit.
It achieves a logarithmic depth with fewer gates than comparable adders such as the Kogge-Stone adder [CITE].
The original motivating idea for this paper was to attempt to quantize the Brett-Kung adder.
Ultimately the result is quite similar to the carry lookahead circuit created by Draper et al \cite{draper2004lookaheadadder}.

Probably the key difference between the construction we will present here, and Draper et al's construction, is that we were trying to take advantage of the ability to uncompute an AND using no Toffoli gates \cite{gidney2018halving}.
We save Toffolis by using more work registers.
This ends up being a net gain whenever the temporary storage of a work qubit consumes less spacetime volume than producing an additional magic state.

To propagate carries quickly, we will be considering various contiguous bit ranges and computing a ternary value that describes the carry behavior of these ranges.
Define the integer slicing operation $k[a:b] = \lfloor k/2^a \rfloor \bmod 2^{b-a+1}$.
Let $x$ and $y$ be the inputs into the addition.
We define

$$C_a^b = \text{median}(0, 2, x[a:b] + y[a:b] - 2^{b - a + 1} + 1)$$

If $C_a^b = 0$, that means the input bits in the range from $a$ to $b$ will produce a carry out bit that is cleared no matter what carry in bit enters into the range.
If $C_a^b = 2$, that means the input bits in the range from $a$ to $b$ will produce a carry out bit that is set no matter what carry in bit enters into the range.
If $C_a^b = 1$, that means the input bits in the range from $a$ to $b$ will produce a carry out bit that is equal to the carry in bit that enters into the range.

Given a bit position, the ternary carry value describing the range from that bit to its successor can be computed like this:

$$\text{unit\_carry}(a) = C_a^{a+1} = (x_a \land y_a) + 2 (x_a \oplus y_a)$$

Note that we have effectively decomposed the ternary carry value into two bits, and that it would take one Toffoli operation to compute this pair of bits.

Ternary carry values whose start and end touch can be fused together, like this:

$$\text{fuse\_carry}(C_a^b, C_b^c) = C_a^c = \begin{cases}
C_b^c = 1 & \rightarrow C_a^b \\
C_b^c \neq 1 & \rightarrow C_b^c
\end{cases}$$

This computation can be performed using two Toffoli operations.
If only one of the bits of the carry value is needed, that bit can be computed using one Toffoli instead of two.

The purpose of creating and fusing carry values together is to discover whether or not $C_0^k < 2$ for each bit position $k$.
This is useful because it tells us whether the bit in the sum at position $k$ should agree or disagree with the parity of $x$ and $y$ at position $k$.
That is to say:

$$(x + y)_k = x_k \oplus y_k \oplus (C_0^k < 2)$$

The main difficulty is in finding a good strategy for fusing carry values, that can perform many fusion steps in parallel but doesn't do too many fusion steps overall.
This is where the Brett-Kung adder comes in: it specifies a fusing pattern that we follow.

We start by computing all unit length ranges $C_k^{k+1}$ in parallel, and fusing these ranges to produce ranges that cross larger distances.
Then, we fuse together range pairs of the form $C_{2k}^{2(k+1/2)}, C_{2(k+1/2)}^{2(k+1)}$ in parallel.
Then, we fuse together range pairs of the form $C_{4k}^{4(k+1/2)}, C_{4(k+1/2)}^{4(k+1)}$ in parallel.
We continue iteratively in this fashion, fusing ranges of the form $C_{2^s 2k}^{2^s (k+1/2)}, C_{2^s (k+1/2) }^{2^s (k+1)}$ in parallel during round $s$, until $2^s$ is larger than the number of bits in the problem.

Once the process of computing the carry values for long distances ranges has completed, we begin using those values to figure out the carry values for ranges starting at 0.
Let $p$ be the largest power of two no larger than $n$.
We happen to already know $C_{0,p}$ from the previous step.
But we also know $C_{p,p+p/2}$, and we can fuse these two carry values to get $C_{0,p+p/2}$.
We continue this process in rounds, where in round $s$ we fuse range pairs of the form $C_{0,p/2^s*k}, C_{p/2^s*k,p/2^s*k+p/2^{s+1}}$ and end up knowing all values $C_{o,k}$ where $k$ is a multiple of $p/2^{s+1}$.
After round $\lg p$ we know all of the carry-from-zero values, and can compute the final sum.
All that's left to do is to reverse the fusing process to uncompute the intermediate range values.

This process is implemented by the \texttt{init\_sum\_using\_carry\_lookahead} method in the \\\texttt{src/adder\_lookahead.qs} ancillary file.

The method as described has a Toffoli cost of $4n$.
This can be somewhat easily seen in the Q\# code, because the only Toffoli operations are \texttt{init\_and} operations initializing the contents of four registers each of size $n$.
The four registers are respectively storing the least significant bits of the carry values for the initial unit length ranges, the $2n$ bits of the carry values created while growing the available ranges, and the $n$ sum-vs-xor parity bits produced while using the grown range carry values to find zero-rooted range carry values.

The reaction depth of the method is $2 \lg n + O(1)$.
The first $\lg n$ comes from growing the ranges.
The remaining $\lg n + O(1)$ comes from using the grown ranges to find zero-rooted ranges, and uncomputing the grown range values in parallel with this step (which can be done because they are used in the reverse order of their initialization and they are no longer needed after they are used).

\begin{figure}
\centering
\resizebox{0.85\linewidth}{!}{
\Qcircuit @R=1em @C=0.75em {
\\
&{/} \qw& \ustick{n}\qw&\gate{\text{input }a}     &\qw       &\qw       &\gate{\text{input }a}              &\qw       &\qw& & & & & & &{/} \qw& \ustick{n}\qw&\qw&\gate{\text{input }a}&\qw&\\
&{/} \qw& \ustick{n}\qw&\gate{\text{input }b} \qwx&\qswap    &\gate{X}  &\gate{\text{input }b}          \qwx&\gate{X}  &\qw& & &=& & & &{/} \qw& \ustick{n}\qw&\qw&\gate{\text{+}a}\qwx&\qw&\\
\lstick{|0\rangle^{\otimes n}}&{/} \qw& \ustick{n}\qw&\gate{\text{init }a+b}\qwx&\qswap\qwx&\gate{X}  &\gate{(\text{init }a+b)^\dagger}\qwx&\qw       &\qw&&&&\lstick{|0\rangle^{\otimes n}}& & & & & & & & \\
\\
}
}
    \caption{
        Converting an out-of-place adder into an in-place adder by running the out-of-place adder forwards and then backwards, with a few additional swap and Pauli operations.
        Swap and Pauli operations can be tracked within the classical control system instead of actually being applied to the qubits.
    }
    \label{fig:oop2ip}
\end{figure}

In order to convert this out-of-place adder into an in-place adder, we use the construction shown in \fig{oop2ip}.
This runs the out-of-place adder forwards, and then backwards, with no other notable cost.
Three allocated registers were uncomputed when computing the out-of-place sum.
When running the out-of-place sum backwards, these registers will be recomputed costing $3n$ Toffolis.
The missing $n$ Toffolis are because the backwards process is not recomputing the sum-vs-xor parity bits; it is uncomputing them.
Therefore the resulting in-place adder has a total Toffoli count of $7n$, a doubled reaction depth of $4 \lg n + O(1)$, and the same workspace cost of $3n$.

\section{Block Lookahead Adder}

To give a sense of where we are going, we will start by describing the simplest possible parallel adder: the two-block-adder.
It divides an $n$-bit addition problem into two $n/2$-bit chunks.
The two-block-adder performs three ripple carry additions in parallel: adding the low chunks with no carry input, adding the high chunks with no carry input, and adding the high chunks with a set carry input.
As soon as the low chunk addition produces a carry output, the carry output is used to decide which of the two high chunk addition results to keep.

Here is pseudo-code describing the two block adder:

\begin{python}
    # Parallel ripple-carry adders.
    let out_low = a_low + b_low carryinto carry_out
    let case0 = a_high + b_high
    let case1 = a_high + b_high + 1
    # Choose high result using carry_out from low half.
    let out_high = case0 if carry_out else case1
    # Uncompute intermediate values in parallel.
    del carry_out
    del case1
    del case0
\end{python}

The ancillary file \texttt{src/adder\_two\_block.qs} has Q\# code implementing this adder.

We can generalize the 2-block-adder into a $m$-block-adder, or equivalently into an adder with blocks of width $b$.
The main difference is that instead of having a single carry out value to work with, we will have $m-1$ to work with.
Fortunately, as part of writing the previous adder we already have a method that can quickly combine local carry values into zero-rooted carry values.
We simply combine these two pieces together.

To start with, we have a $2n$ Toffoli count overhead due to needing to compute both carry cases for most of the blocks and then a further $n$ Toffolis used to control which case gets written as the result for each block.
The remaining costs have to do with propagating the carries.
However, because we only get one carry per block instead of one per bit, these costs are lower than they were in the carry lookahead case.
Also, we happen to have computed values that can be turned into one of the four registers we needed.
The result is that we pay $3n/b$ Toffolis where $b$ is the block size.
Even if we use a low block size of $b = 4$, we are outperforming our per-bit carry lookahead adder.
We're even using less workspace; the only place we pay is in the depth.

Actually, given how extreme the factory requirement is, it makes sense to pay quite a lot of depth.
A reasonable Schelling point to set the block size is $\sqrt{n}$, because this is where costs that grow like $b$ start to overtake costs that grow like $n/b$.
The result is an adder with bla bla bla.
As we show in table bla, this is the best performing adder at the largest case we estimated.

\section{Comparison}


\section{Conclusion}

Adder good.

\bibliographystyle{plain}
\bibliography{references}
\end{document}
